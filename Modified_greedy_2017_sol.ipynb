{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "from random import random as rnd\n",
    "from random import gauss, randrange\n",
    "import random\n",
    "from datetime import datetime\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"./me_at_the_zoo.in\"\n",
    "#path = \"./videos_worth_spreading.in\"\n",
    "#path = \"./trending_today.in\"\n",
    "path = \"./kittens.in.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_latency(a):\n",
    "    difference_to_endpoints = {}\n",
    "    endpoints_to_video = list_endpoints[a[0]]\n",
    "    for endpoint in endpoints_to_video:\n",
    "        difference_to_endpoints[endpoint] = request_dict[(endpoint, a[0])]*(a[2] if (endpoint,a[1]) in latency else 0)\n",
    "    for c in lat_gain[a[0]]:\n",
    "            reduction_in_lat_gain = sum([difference_to_endpoints[endpoint] for endpoint in endpoints_to_video if (endpoint, c) in latency])\n",
    "            lat_gain[a[0]][c] = (lat_gain[a[0]][c]*sizes_videos[a[0]]-reduction_in_lat_gain)/sizes_videos[a[0]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path) as f:\n",
    "    V, E, R, C, X = [int(x) for x in next(f).split()]\n",
    "    sizes_videos = [int(x) for x in next(f).split()]\n",
    "    endpoints = []\n",
    "    for i in range(E):\n",
    "        datacen_lat, num_caches = [int(x) for x in next(f).split()]\n",
    "        connection = []\n",
    "        for j in range(num_caches):\n",
    "            ep_lat = [int(x) for x in next(f).split()]\n",
    "            connection.append(ep_lat)\n",
    "        endpoints.append([datacen_lat, num_caches, connection])\n",
    "    requests = []\n",
    "    for i in range(R):\n",
    "        requests.append([int(x) for x in next(f).split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a latency map\n",
    "\n",
    "latency = {}\n",
    "# (endpoint, cache) -> latency\n",
    "for i in range(E):\n",
    "    latency[(i,-1)] = endpoints[i][0]\n",
    "    for j in range(endpoints[i][1]):\n",
    "        latency[(i,endpoints[i][2][j][0])] = endpoints[i][2][j][1]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_dict = {}\n",
    "# (endpoint, video) -> num_request\n",
    "for i in range(R):\n",
    "    request_dict[(requests[i][1], requests[i][0])] = requests[i][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video -> list of endpoints requesting it\n",
    "list_endpoints = {}\n",
    "for i in range(V):\n",
    "    list_endpoints[i] = []\n",
    "for i in range(R):\n",
    "    list_endpoints[requests[i][0]].append(requests[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map for latency gain\n",
    "lat_gain = {}\n",
    "# (video)-> (cache) -> if added then what is gained latency at the moment\n",
    "for v in range(V):\n",
    "    lat_gain[v] = {}\n",
    "    for c in range(C):\n",
    "        original_latency = sum([(latency[(list_endpoints[v][x],-1)])*request_dict[(list_endpoints[v][x],v)] for x in range(len(list_endpoints[v]))])\n",
    "        #latency[(2,0)]\n",
    "        reduced_latency = sum([(latency[(list_endpoints[v][x], c)])*request_dict[(list_endpoints[v][x],v)] for x in range(len(list_endpoints[v])) if (list_endpoints[v][x],c) in latency])\n",
    "        lat_gain[v][c] = (original_latency - reduced_latency)/sizes_videos[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "max_lat_list = []\n",
    "for v in range(V):\n",
    "    #tuple (v, cache, lat_gain_value)\n",
    "    max_lat_list.append((v, max(lat_gain[v].items(), key=operator.itemgetter(1))[0], max(lat_gain[v].items(), key=operator.itemgetter(1))[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_availability = [X for i in range(C)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-b7bbd71bc9d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfinal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_lat_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "final_result = []\n",
    "for i in range(V*C):\n",
    "    a = max(max_lat_list, key = operator.itemgetter(2))\n",
    "    if sizes_videos[a[0]] <= size_availability[a[0]]:\n",
    "        final_result.append((a[0], a[1]))\n",
    "        size_availability[a[0]] = size_availability[a[0]] - sizes_videos[a[0]]\n",
    "        del lat_gain[a[0]][a[1]]\n",
    "        update_latency(a)\n",
    "        max_lat_list[a[0]] = (a[0], max(lat_gain[a[0]].items(), key=operator.itemgetter(1))[0], max(lat_gain[a[0]].items(), key=operator.itemgetter(1))[1])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
